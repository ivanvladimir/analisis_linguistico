{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7a934a-b7a9-4532-95ca-3f025fb74b5d",
   "metadata": {},
   "source": [
    "# Análisis de datos lingüisticos\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ivanvladimir/analisis_linguistico/blob/main/Análisis de corpus.ipynb)\n",
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/ivanvladimir/analisis_linguistico/blob/main/An%C3%A1lisis%20de%20corpus.ipynb)\n",
    "\n",
    "Este es el código para ejemplificar análisis computacional lingüístico.\n",
    "\n",
    "### Instrucciones\n",
    "\n",
    "Ejecutar las celdas en el orden que se encuentran.\n",
    "\n",
    "### Licencia de la notebook\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/80x15.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
    "\n",
    "### Información general\n",
    "\n",
    "> **Author(s)**: <a href=\"https://twitter.com/ivanvladimir\">@ivanvladimir</a> </br>\n",
    "> **Last updated**: 15/06/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eccd19-cc2e-42a7-8a5e-1f2e4c515cbc",
   "metadata": {},
   "source": [
    "# ❶  Preparar librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8fd58-f1f4-4a6d-9116-fe871a9fd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar librerias\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b071fc-f0cb-4b28-90c7-2504f3af6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa448d-1eec-47d7-b72a-0fb81883aab6",
   "metadata": {},
   "source": [
    "# ❷ Preparar datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc129b5-38bd-4147-82e3-4f1cd53acb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bajar datos mañanera\n",
    "!git clone https://github.com/NOSTRODATA/conferencias_matutinas_amlo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18dbd2-eeb1-4546-8777-0c4c152b2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner todos los datos en un dataframe\n",
    "\n",
    "dataframes=[]\n",
    "\n",
    "for root, dirs, files in os.walk(\"conferencias_matutinas_amlo/\", topdown=False):\n",
    "   for name in files:\n",
    "      if name.startswith('mananera') and name.endswith(\".csv\"):\n",
    "        try:\n",
    "            filename=os.path.join(root,name)\n",
    "            df = pd.read_csv(filename)\n",
    "            df['source_file'] = filename\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "try:\n",
    "    df = pd.concat(dataframes, ignore_index=True, sort=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error combining dataframes: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1b5b1-e120-4b5a-abc1-ff299e1ce309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f39c2-6639-4ad0-97fa-c8aeaf264eb2",
   "metadata": {},
   "source": [
    "# ❸ Calcular concordancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ec91d-8c2f-4767-8742-8b09de090b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text, ConcordanceIndex\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = '\\n'.join(df[df['Participante']=='PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR']['Texto'].astype(str))\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "concordance_index = ConcordanceIndex(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8eedc6-daa0-4cde-b75b-85e2c31e4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = concordance_index.offsets(\"Pemex\")\n",
    "width=60\n",
    "concordances = []\n",
    "\n",
    "for offset in offsets:\n",
    "    # Calculate context boundaries\n",
    "    left_start = max(0, offset - width)\n",
    "    right_end = min(len(tokens), offset + width + 1)\n",
    "    \n",
    "    # Extract contexts\n",
    "    left_context = tokens[left_start:offset]\n",
    "    keyword = tokens[offset]\n",
    "    right_context = tokens[offset + 1:right_end]\n",
    "    \n",
    "    concordances.append({\n",
    "        'position': offset,\n",
    "        'left_context': left_context,\n",
    "        'keyword': keyword,\n",
    "        'right_context': right_context,\n",
    "        'left_text': ' '.join(left_context),\n",
    "        'right_text': ' '.join(right_context),\n",
    "        'full_context': ' '.join(tokens[left_start:right_end])\n",
    "    })\n",
    "\n",
    "print(f\"Total de concordancias {len(concordances)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af1d00-0e0f-4a86-bf50-8e42c788f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INI=0\n",
    "FIN=20\n",
    "\n",
    "for conc in concordances[INI:FIN]:\n",
    "    print(f\"{conc['left_text'][-width:]:>60} [{conc['keyword']}] {conc['right_text'][:width]:<60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9662be-1a25-4f6e-8bef-6f0410cd04b6",
   "metadata": {},
   "source": [
    "# ❹ Calcular colocaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae0631-dce6-4eda-8ec0-a556f608ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "min_freq=2\n",
    "num_collocations=20\n",
    "\n",
    "# Remove stopwords and punctuation\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "tokens = [token for token in tokens \n",
    "          if token not in stop_words and token not in string.punctuation]\n",
    "\n",
    "# Bigram collocations\n",
    "bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "bigram_finder.apply_freq_filter(min_freq)\n",
    "\n",
    "# Different scoring methods\n",
    "print(\"=== BIGRAM COLLOCATIONS ===\")\n",
    "\n",
    "print(f\"\\nTop {num_collocations} by PMI (Pointwise Mutual Information):\")\n",
    "pmi_bigrams = bigram_finder.nbest(BigramAssocMeasures.pmi, num_collocations)\n",
    "for bigram in pmi_bigrams:\n",
    "    print(f\"  {bigram[0]} {bigram[1]}\")\n",
    "\n",
    "print(f\"\\nTop {num_collocations} by Chi-square:\")\n",
    "chi_sq_bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, num_collocations)\n",
    "for bigram in chi_sq_bigrams:\n",
    "    print(f\"  {bigram[0]} {bigram[1]}\")\n",
    "\n",
    "print(f\"\\nTop {num_collocations} by Likelihood Ratio:\")\n",
    "likelihood_bigrams = bigram_finder.nbest(BigramAssocMeasures.likelihood_ratio, num_collocations)\n",
    "for bigram in likelihood_bigrams:\n",
    "    print(f\"  {bigram[0]} {bigram[1]}\")\n",
    "\n",
    "# Trigram collocations\n",
    "trigram_finder = TrigramCollocationFinder.from_words(tokens)\n",
    "trigram_finder.apply_freq_filter(min_freq)\n",
    "\n",
    "print(f\"\\n=== TRIGRAM COLLOCATIONS ===\")\n",
    "print(f\"\\nTop {num_collocations//2} by PMI:\")\n",
    "pmi_trigrams = trigram_finder.nbest(TrigramAssocMeasures.pmi, num_collocations//2)\n",
    "for trigram in pmi_trigrams:\n",
    "    print(f\"  {trigram[0]} {trigram[1]} {trigram[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7522212-c468-4bc3-abdb-e5fa823c44ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
