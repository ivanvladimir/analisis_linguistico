{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7a934a-b7a9-4532-95ca-3f025fb74b5d",
   "metadata": {},
   "source": [
    "# Análisis meta lingüisticos\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ivanvladimir/analisis_linguistico/blob/main/Analisis%20metalinguisticos.ipynb)\n",
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/ivanvladimir/analisis_linguistico/blob/main/Analisis%20metalinguisticos.ipynb)\n",
    "\n",
    "Este es el código para ejemplificar análisis computacional lingüístico: metalingüísticos.\n",
    "\n",
    "### Instrucciones\n",
    "\n",
    "Ejecutar las celdas en el orden que se encuentran.\n",
    "\n",
    "### Licencia de la notebook\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/80x15.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
    "\n",
    "### Información general\n",
    "\n",
    "> **Author(s)**: <a href=\"https://twitter.com/ivanvladimir\">@ivanvladimir</a> </br>\n",
    "> **Last updated**: 15/06/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eccd19-cc2e-42a7-8a5e-1f2e4c515cbc",
   "metadata": {},
   "source": [
    "# ❶  Preparar librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dccf21-e9f3-4c75-a2d8-829399648494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librerias\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8fd58-f1f4-4a6d-9116-fe871a9fd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar librerias\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa448d-1eec-47d7-b72a-0fb81883aab6",
   "metadata": {},
   "source": [
    "# ❷ Cargar modelo \n",
    "\n",
    "Potencialmente probar con\n",
    "\n",
    "* [facebook/roberta-hate-speech-dynabench-r4-target](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target)\n",
    "* [pysentimiento/robertuito-sentiment-analysis](https://huggingface.co/pysentimiento/robertuito-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc129b5-38bd-4147-82e3-4f1cd53acb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"pysentimiento/robertuito-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"pysentimiento/robertuito-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f39c2-6639-4ad0-97fa-c8aeaf264eb2",
   "metadata": {},
   "source": [
    "# ❸ Usar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18dbd2-eeb1-4546-8777-0c4c152b2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSG=\"Yo creo que el día de hoy habrá mucho sol y será un día excelente\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = tokenizer(MSG, return_tensors=\"pt\")\n",
    "    logits = model(**tokens).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578dc7d-1d75-49fd-8229-68c32fe2a1e9",
   "metadata": {},
   "source": [
    "# ❹ Explorando la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8eedc6-daa0-4cde-b75b-85e2c31e4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7522212-c468-4bc3-abdb-e5fa823c44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Token IDs: {tokens['input_ids'].tolist()[0]}\")\n",
    "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])}\")\n",
    "print(f\"Decoded: {tokenizer.decode(tokens['input_ids'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd77c2-dd8d-4908-84d5-ff57ef7dc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bacbb4-1ac0-453f-b621-cede7b55958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "probs = F.softmax(logits, dim=1)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6680991-2676-4ba7-96e5-d2e95d55d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print({v: f\"{float(probs[0][k])*100:3.2f}%\" for k,v in model.config.id2label.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ae2d9-0855-46fc-bd65-ffa80f2c07a7",
   "metadata": {},
   "source": [
    "# ❺ Modelos para segmento de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdd1fa-6897-4b69-b603-1d95bf2c8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"SIRIS-Lab/citation-parser-ENTITY\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"SIRIS-Lab/citation-parser-ENTITY\")\n",
    "\n",
    "# Get label names\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "\n",
    "text=\"Robles, C. , Carrillo, M. and Meza, I. : Detección de emociones en texto en español utilizando transformers. Abstraction & Application. Vol. 47. pp. 87-97. 2024\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "labels = [id2label[pred.item()] for pred in predictions[0]]\n",
    "\n",
    "# Extract entities\n",
    "entities = []\n",
    "current_entity = []\n",
    "current_label = None\n",
    "\n",
    "for token, label in zip(tokens, labels):\n",
    "    if token in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "        continue\n",
    "        \n",
    "    if label.startswith('B-'):  # Beginning of entity\n",
    "        if current_entity:  # Save previous entity\n",
    "            entities.append({\n",
    "                'text': tokenizer.convert_tokens_to_string(current_entity),\n",
    "                'label': current_label\n",
    "            })\n",
    "        current_entity = [token]\n",
    "        current_label = label[2:]  # Remove 'B-' prefix\n",
    "        \n",
    "    elif label.startswith('I-') and current_label == label[2:]:  # Inside entity\n",
    "        current_entity.append(token)\n",
    "        \n",
    "    else:  # Outside entity or different entity\n",
    "        if current_entity:\n",
    "            entities.append({\n",
    "                'text': tokenizer.convert_tokens_to_string(current_entity),\n",
    "                'label': current_label\n",
    "            })\n",
    "        current_entity = []\n",
    "        current_label = None\n",
    "\n",
    "# Don't forget the last entity\n",
    "if current_entity:\n",
    "    entities.append({\n",
    "        'text': tokenizer.convert_tokens_to_string(current_entity),\n",
    "        'label': current_label\n",
    "    })\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"  {entity['text']} -> {entity['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85db1f-78eb-400c-8abd-19b49350804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the model\n",
    "citation_parser = pipeline(\"ner\",\n",
    "                           model=\"nicolauduran45/patstat-citation-parser\",\n",
    "                           tokenizer=\"nicolauduran45/patstat-citation-parser\",\n",
    "                           aggregation_strategy=\"simple\")\n",
    "\n",
    "citation_text=\"Alizadeh, P. , Garcia, J. , Meza, I. and Taleb, S. : Reinforcement Learning for Expert Finding from Web Search Results. Advances in Knowledge Discovery and Management. pp. 113-128. 2024.\"\n",
    "# Parse the citation\n",
    "entities = citation_parser(citation_text)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"  {entity['word']} -> {entity['entity_group']} (confidence: {entity['score']:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
